params:
  num_epochs: 10
  batch_size: 16
  lr: 5.0e-7
  early_stop_threshold: 3
  scheduler: constant       # constant, linear
  warmup_steps: 0
  model_head: multilabel

paths:
  train_data: "./data/df_train.pkl"
  val_data: "./data/df_val.pkl"
  roberta_config: "./config/roberta_config.yaml"
  tknz: "./tokenizer"