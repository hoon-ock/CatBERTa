vocab_size: 50265   # vocab size of the tokenizer (default: 50_265)
max_position_embeddings: 770  # e.g. 768 + 2 (positional embedding offset)
hidden_size: 768 # multiple of (num_attention_heads)
num_attention_heads: 12
num_hidden_layers: 12
type_vocab_size: 1